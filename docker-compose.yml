version: "3.8"

services:
  db:
    image: postgres:15
    environment:
      POSTGRES_USER: username # The PostgreSQL official image will create this user.
      POSTGRES_PASSWORD: password # And set this password for the user.
      POSTGRES_DB: postgresdb # And create this database, owned by the user.
      # Note: The 'postgres' superuser is also created by the image.
      # While a manual PostgreSQL installation requires setting a password for the 'postgres' user,
      # for this Docker setup, you'll primarily interact with the database using the credentials
      # specified by POSTGRES_USER and POSTGRES_PASSWORD. The 'postgres' user will have a
      # randomly generated password by default if POSTGRES_PASSWORD is not set for it, 
      # or you can set POSTGRES_HOST_AUTH_METHOD=trust for local development if needed (not recommended for production).
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - default

  web:
    build: .
    # Run migrations before starting the app
    # Ensure alembic is installed (it should be via requirements.txt)
    # The working directory is /app/src, but alembic.ini is in /app, so we cd ..
    command: sh -c "cd .. && alembic upgrade head && cd src && uvicorn main:app --host 0.0.0.0 --port 8000 --reload"
    volumes:
      - ./src:/app/src
      - ./alembic.ini:/app/alembic.ini
      - ./migrations:/app/migrations
      - ./.env:/app/.env
    ports:
      - "8000:8000"
    depends_on:
      - db
    env_file:
      - .env
    working_dir: /app/src

  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    networks:
      - default
    
  celery_worker:
    build: .
    command: celery -A src.celery.celery_app worker -l info
    volumes:
      - ./src:/app/src
      - ./.env:/app/.env # Ensure .env is available in the container
    depends_on:
      - db
      - redis
    env_file:
      - .env
    working_dir: /app/src # Important for relative imports in celery tasks

  celery_beat:
    build: .
    # The command for beat should use the beat subcommand, not worker
    # Using DatabaseScheduler, ensure django-celery-beat is in requirements.txt if you use it
    # For now, using default scheduler. If DatabaseScheduler is needed, add dependency and migrations.
    command: celery -A src.celery.celery_app beat -l info # --scheduler django_celery_beat.schedulers:DatabaseScheduler
    volumes:
      - ./src:/app/src
      - ./.env:/app/.env # Ensure .env is available
    depends_on:
      - db
      - redis
      # It's good practice for beat to depend on the worker, or at least ensure broker is ready.
      # - celery_worker 
    env_file:
      - .env
    working_dir: /app/src # Important for relative imports
  
volumes:
  postgres_data:
